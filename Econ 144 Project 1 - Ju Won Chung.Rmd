---
title: "Econ 144 Project 1"
author: 
- "Ju Won Chung"
- "Instructor: Dr. Rojas"
- "UCLA Winter 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tis)
library(forecast)
library(ggplot2)
library(gridExtra) 
library(MASS)

setwd("C:\\Users\\jjoshuac714\\Desktop\\Econ 144\\Week 3")

sales_em <- read.csv("ESHOP&MAIL.csv")
sales_em <- ts(sales_em[,2], 1992, c(2019,11), freq = 12)
t <- ts(sales_em, frequency = 12, start = c(1992, 01), end = c(2019, 11))
t <- as.numeric(time(t))
```

> # I. __Introduction__
> ### Background
 #### The dataset I am using is Retail Sales: Electronic Shopping and Mail-order Houses from _fred.st.louisfed.org_. This subset industry within U.S retail is defined by "establishments primarily engaged in retailing all types of merchandise using nonstore means" which includes catalogs, electronic media etc. The data is observed monthly from January 1, 1992 to November 1, 2019 for a total of 335 observations. Retail sales in e-shopping and mail-order houses is measured in millions of dollars. 
 ### Goal
 #### I want to take into account factors such as seasonal consumer behavior and overall changes in trend due to technological progress in order to better understand the success and inner workings of these 2 aspects of convenient retail evolutions and forecast future values to gain insight in potential prospects of this ever growing industry. 

> # II. __Results__
> ## 1. Modeling and Forecasting Trend

> ### a) Time Series Plot 
```{r, echo = FALSE}
plot(sales_em, main = "Retail Sales: Electronic Shopping and \nMail-Order Houses", 
     xlab = "Time", ylab = "$ in millions")
nberShade()
lines(sales_em)

```

> ### b)

> #### The plot suggests that this time series is nonstationary rather than covariance stationary. This data has a clear upward trend with no stable expected mean throughout time while also showing increasing variance.

```{r, include = FALSE}
sales_total <- read.csv("TOTRTRADES.csv", header = FALSE)
sales_total <- as.numeric(gsub(",","",sales_total[,1]))

```

```{r, echo = FALSE}
par(mfrow = c(2,1))
plot(sales_em, main = "Retail Sales: Electronic Shopping and \nMail-Order Houses", 
     xlab = "Time", ylab = "$ in millions")
nberShade()
lines(sales_em)
plot(t, sales_total, type = "l", main = "Retail Sales: Total (including Food Services)",
     xlab = "Time", ylab = "$ in millions")
nberShade()
lines(t, sales_total, col = "navyblue")
par(mfrow = c(1,1))

```

> #### Following the characteristics of Total Retail sales, E-Shopping and Mail-Orders sales also gradually increase when the U.S economy is strong and falls off during recessions. However, it is not impacted as much and the declines in sales are not as drastic, as can be visualized. Another key difference is that sales during Christmas season have volatility with much higher peaks as time passes as opposed to the fairly stable variance in Total Sales. This indicates that the market for online retail is constantly increasing and may have even more growth opportunities as consumers move toward convenient shopping.  

 * #### This change in variance over time may complicate the forecasting process and will likely require smoothing.

> ### c) Autocorrelations of "sales_em" (Sales from E-Shopping & Mail-order)
```{r, echo = FALSE}
ggAcf(sales_em)
ggPacf(sales_em)

```

> #### The ACF shows slowly decreasing lags, indicating that autocorrelation lasts for a long period of time (persistence). The PACF reveals that there are a multitude of significant lags beyond the initial 3. The second longest spike at Lag 13 seems to be due to the increasing variance over time (~ every year) possibly explained by consumer behavior leaning towards online shopping or simply an increasing U.S population. Together, these measurements strongly suggest an S-AR (seasonal autoregressive) model as the plot also reflects.

> ### d) Linear Model and Natural Log Model Fits
```{r, echo = FALSE}
t_mod1 <- tslm(sales_em ~ trend)
plot1 <- ggplot() + geom_line(data = as.data.frame(sales_em), aes(x = t, y = sales_em[1:335])) +
      geom_line(data = as.data.frame(t_mod1$fit), aes(x = t, y = t_mod1$fit), col = "red", lwd = 1) +
      ggtitle("Trend Model 1") +
      ylab("sales_em") +
      xlab("Time") 

lsales_em <- log(sales_em)
t_mod2 <- tslm(lsales_em ~ trend)
plot2 <- ggplot() + geom_line(data = as.data.frame(sales_em), aes(x = t, y = lsales_em[1:335])) +
      geom_line(data = as.data.frame(t_mod2$fit), aes(x = t, y = t_mod2$fit), col = "red", lwd = 1) +
      ggtitle("Trend Model 2") +
      ylab("ln(sales_em)") +
      xlab("Time")

grid.arrange(plot1, plot2, nrow = 2)

```

> * #### Here, the original data is logged to stabilize the variance as discussed before 

> ### e) Residuals vs. Fitted Values
```{r, echo = FALSE}
plot3 <- ggplot() + geom_point(aes(x = as.numeric(t_mod1$fit), y = as.numeric(t_mod1$res))) +
      geom_line(aes(x = as.numeric(t_mod1$fit), y = 0), col = "red") +
      geom_line(aes(x = 0, y = t_mod1$res), col = "red") +
      ggtitle("Trend Model 1") +
      xlab("Fitted Values") +
      ylab("Residuals")
plot3
```

> #### In the linear plot (model 1), the bulk of the residuals seem to reflect overestimated values as shown by the points below line y = 0. However, the tail ends are underestimated (above y = 0), though in the right tail the increasing in values increase faster in residuals. This is likely due to the linear model's inability in capturing the increasing volatility over time. 

```{r, echo = FALSE}
plot4 <- ggplot() + geom_point(aes(x = as.numeric(t_mod2$fit), y = as.numeric(t_mod2$res))) +
      geom_line(aes(x = as.numeric(t_mod2$fit), y = 0), col = "red") +
      ggtitle("Trend Model 2") +
      xlab("Fitted Values") +
      ylab("Residuals")
plot4
```

> #### In the natural log plot (model 2), the residuals seem more randomly scattered with a few exceptions. The middle area (x = ~ 9, 9.7) has both fewer and smaller magnitude values of overestimation than both the horizontal left and right tails. Looking at the ln plot of sales_em, the gray recession bands seemingly reflect this lack of overestimation and abundance of underestimation of sales. 
```{r, echo = FALSE}
plot4a <- plot4 + geom_line(aes(x = 9.05, y = as.numeric(t_mod2$res)), col = "skyblue2", lwd = 0.25) + geom_line(aes(x = 9.7, y = as.numeric(t_mod2$res)), col = "skyblue2", lwd = 0.25)

plot4a
plot(lsales_em, main = "Retail Sales: Electronic Shopping and \nMail-Order Houses", 
     xlab = "Time", ylab = "ln(sales_em)")
nberShade()
lines(lsales_em)
abline(h = 9.05, col = "skyblue2")
abline(h = 9.7, col = "skyblue2")

```

> #### The light blue lines indicate the decrease in sales during recessions (gray bands) which correspond to the high underestimation of many values (in Trend Model 2) along with nearly no overestimation during this time period. 

> ### f) Distribution of Residuals 
```{r, echo = FALSE}
truehist(t_mod1$res, col = "skyblue", xlab = "Residuals", ylab = "Fraction",
         main = "Trend Model 1 \nResiduals Histogram", xlim = c(-20000, 20000))
xr <- rnorm(1000000, mean(t_mod1$res), sd(t_mod1$res))
lines(density(xr), col = "red", lwd = 2)
lines(density(t_mod1$res), col = "darkblue", lwd = 2)
legend(x = "topright", legend = c("Density", "Normal Distribution"), 
       col = c("darkblue", "red"), lty = 1, lwd = 2, bty = "n")
```

> #### The residuals of model 1 looks somewhat like a normal distribution but is not symmetric and displays a right skewness. The bulk of the model 1 residuals due to some overestimation are around -50,000 as shown by both the histogram and previous residual vs fit plot.

```{r, echo = FALSE}
truehist(t_mod2$res, col = "skyblue", xlab = "Residuals", ylab = "Fraction",
         main = "Trend Model 2 \nResiduals Histogram", xlim = c(-0.6, 0.6))
xr <- rnorm(1000000, mean(t_mod2$res), sd(t_mod2$res))
lines(density(xr), col = "red", lwd = 2)
lines(density(t_mod2$res), col = "darkblue", lwd = 2)
legend(x = "topright", legend = c("Density", "Normal Distribution"), 
       col = c("darkblue", "red"), lty = 1, lwd = 2, bty = "n")

```

> #### The residuals of model 2 seems to have a fair resemblance to a normal distribution. The distribution is slightly taller and thinner, showing that the density of residuals around 0 is proportionately even greater than the normal distribution. Overall, model 2 seems a closer to normal than model 1.

> ### g) Summary Statistics
```{r, echo = FALSE}
summary(t_mod1)
```

> #### Model 1 has a strong R^2 of 0.8535 which shows that it explains the data very well. The t-stats (absolute value) of both the intercept and t are significant, with corresponding low p-values that pass significance tests well past 1%. The high f-stat and its low p-value reflect the model as significant as a whole.

```{r, echo = FALSE}
summary(t_mod2)

```

> #### Model 2 has an even stronger R^2 at .9676 which is extremely closed fit. The t-stats and p-values of the intecept and t are also significant at very low levels. The same can be said for the whole model, which is supported by a much higher f-stat and low p-value.

> ### h) Model Selection Criteria
```{r, echo = FALSE}
AIC(t_mod1, t_mod2)
BIC(t_mod1, t_mod2)

```

> #### Model 2 has a lower AIC and BIC than Model 1 in both actual and absolute value, revealing a clear agreement that Model 2 is a better fit according to these model selection criteria. 

> ### i) 5 Year Ahead (h = 60) Trend Forecast
> * #### lsales_em = ln(sales_em) 
```{r, echo = FALSE}
fore1 <- forecast(t_mod2, h = 60)
plot(fore1, main = "Trend Model 2", xlab = "Time", ylab = "lsales_em")
legend(x = "bottomright", legend = c("80% Prediction Interval", "95% Prediction Interval"), 
       fill = c("lightsteelblue3", "gray87"), bty = "n", cex = 1)
legend(x = "bottom", "Point Forecast", col = "blue", lty = 1, lwd = 1.5, 
       bty = "n", cex = 1)

```

> ## 2. Implementing a Seasonality model 

> ### a) Seasonal Patterns 
```{r, echo = FALSE}
ggsubseriesplot(sales_em)
ggseasonplot(sales_em)
```

> #### * The seasonal trend of increase in sales near month-end in the original dataset is confirmed here.

> ### Seasonal Dummy Model based on lsales_em
```{r, echo = FALSE}
par(mfrow = c(2,1))
s_mod1 <- tslm(lsales_em ~ season + 0)
summary(s_mod1)
plot(s_mod1$fit, xlim = c(1992, 2020), ylab = "Seasonal Model 1", 
     main = "Seasonal Component of Dummy Model")

s_lsales_em <- stl(lsales_em, s.window = "periodic")
s_lsales_em <- s_lsales_em$time.series[,1]
plot(s_lsales_em, ylab = "Seasonal ln(sales_em)", main = "Seasonal Adjustment using\nSTL Decomposition")
par(mfrow = c(1,1))

```

> ### b)
```{r, echo = FALSE}
par(mfrow = c(2,1))
plot(s_mod1$coef, type = "l", main = "Seasonal Factors", xlab = "Season",
     ylab = "Seasonal Factors", lwd = 2, col = "forestgreen")
hist(s_mod1$res, main = "Histogram of Residuals", col = "steelblue2", xlim = c(-2, 2), xlab = "Seasonal Model 1 Residuals")

```

> #### The significance testing of the all the seasons (including Season 1) results in Factors that are all significant at very low levels and increase in magnitude as Season increases (especially at 9 to 12).

> ### c) Residuals vs. Fitted Values
```{r, echo = FALSE}
par(mfrow = c(1,1))
full_mod <- tslm(lsales_em ~ trend + season) 
plot5 <- ggplot() + geom_point(aes(x = as.numeric(full_mod$fit), y = as.numeric(full_mod$res))) +
      geom_line(aes(x = as.numeric(full_mod$fit), y = 0), col = "red") +
      ggtitle("Full Model") +
      xlab("Fitted Values") +
      ylab("Residuals")
plot5
```

Comparison to Trend Model 2 (lsales_em)

```{r, echo = FALSE}
grid.arrange(plot5 + ylim(-0.4, 0.4), plot4, nrow = 2)

```

> #### The residual vs fit plot of the Full Model is very similar in structure to the residual vs fit plot of Model 2 (ln(sales_em)). However, in this case, the variance of the residuals is much more even than previous models. It seems that the drastic underestimated outlier values have disappeared. There still remains some slight pattern which may reflect the full model lacking some significant aspect of the data.  

> ### d) Summary Statistics and Error Metrics
```{r, echo = FALSE}
summary(full_mod)
```

> #### The summary statistics of the Full Model shows significant fits of the intercept, trend fit, and seasonal fit. The R^2 is at 0.9883 which reflects a very accurate model and a high f stat with a very low p-value which support the model as significant. 

```{r, echo = FALSE}
AIC(t_mod1, t_mod2, s_mod1, full_mod)
BIC(t_mod1, t_mod2, s_mod1, full_mod)
```
```{r}
accuracy(full_mod)
accuracy(t_mod2)

```

> #### AIC and BIC shows that the Full Model is a better model than both Model 1 and Model 2. The error metrics (comparing full_mod with the next best model: t_mod2) which show much lower errors in comparison confirm this.

> ### e) 5 Year Ahead (h = 60) Full Forecast
```{r, echo = FALSE}
fore2 <- forecast(full_mod, h = 60)
plot(fore2, main = "Full Model", xlab = "Time", ylab = "lsales_em")
plot(fore2, main = "Full Model", xlab = "Time", ylab = "lsales_em",
     xlim = c(2017, 2025))
legend(x = "bottomright", legend = c("80% Prediction Interval", "95% Prediction Interval"), 
       fill = c("lightsteelblue3", "gray87"), bty = "n", cex = 1.1)
legend(x = "bottomleft", "Point Forecast", col = "blue", lty = 1,
       lwd = 2, bty = "n", cex = 1.1)

```


> # III. __Conclusions and Future Work__
> #### Though initially the data plot seemed to present a potential problem in modelling and forecasting due to the volatility of the variance over time, logging the dataset proved to stabilize the variance and smooth the trendline. 
 #### The final model which makes use of both seasonal and trend dummies has a very close looking fit to the natural log of the sales data. Overall, the forecast seems very plausible due to the simplistic nature of the increasing values at a stable pace. 
 #### In the end, the leftover residual patterns (possibly cyclical) were not accounted for. The model could also potentially be improved if the seasonal component could be captured even more accurately (perhaps using different methods of decomposition e.g X11, SEATS etc). Finally, given the somewhat lacking number of observations due to the nature of the data, more time and thus more data could further improve the model in accuracy and predictive power.

> # IV. __References__
> * _Federal Reserve Bank of St. Louis (Retail Sales: E-Shopping & Mail-Order Data)_:
> https://fred.stlouisfed.org/series/MRTSSM4541USN?utm_source=series_page&utm_medium=related_content&utm_term=other_formats&utm_campaign=other_format
> * _U.S Census Bureau (Definitions)_:
> https://www.census.gov/cgi-bin/sssd/naics/naicsrch?code=454110&search=2017%20NAICS%20Search
> * https://www.census.gov/retail/definitions.html
> * _U.S Census Bureau (Total Retail Trade Data)_:
> https://www.census.gov/econ/currentdata/dbsearch?program=MRTS&startYear=1992&endYear=2019&categories=44X72&dataType=SM&geoLevel=US&notAdjusted=1&submit=GET+DATA&releaseScheduleId=

> # V. __R Source code__

```{r, results = "hide", message = FALSE}
setwd("C:\\Users\\jjoshuac714\\Desktop\\Econ 144\\Week 3") #set working directory
library(lattice)                                           #load packages
library(foreign)
library(MASS)
library(car)
require(stats)
require(stats4)
library(KernSmooth)
library(fastICA)
library(cluster)
library(leaps)
library(mgcv)
library(rpart)
library(pan)
library(mgcv)
library(DAAG)
library("TTR")
library(tis)
require("datasets")
require(graphics)
library("forecast")
require(astsa)
library(RColorBrewer)
library(plotrix)
library(nlstools)
library(seasonal)
library(fpp2)
library(forecast)
library(dynlm)
library(Hmisc)
library(ggplot2)
library(gridExtra)
```

> ### 1. Modeling and Forecasting Trend

> ##### a) Creating time series plot
```{r, results = "hide", message = FALSE, fig.show = "hide"}
sales_em <- read.csv("ESHOP&MAIL.csv")       #store csv datset as data frame "sales_em"
sales_em <- ts(sales_em[,2], 1992, c(2019,11), freq = 12) #transform into time series
t <- ts(sales_em, frequency = 12, start = c(1992, 01), end = c(2019, 11))
t <- as.numeric(time(t))                     #create numeric time dummy vector that corresponds to sales_em data

plot(sales_em, main = "Retail Sales: Electronic Shopping and \nMail-Order Houses", 
     xlab = "Time", ylab = "$ in millions")  #plot time series
nberShade()                                  #add gray recession bands
lines(sales_em)                              #overlay plot over gray bands

```

> ##### b) Comparison with Total Retail plot to help explain covariance stationary
```{r, results = "hide", message = FALSE, fig.show = "hide"}  
sales_total <- read.csv("TOTRTRADES.csv", header = FALSE) 
                                  #store total retail trades dataset as data frame "sales_total"
sales_total <- as.numeric(gsub(",","",sales_total[,1]))  
                                  #subset only sales values ([,column1]) and remove commas as a numeric    


par(mfrow = c(2,1))                                   #shrink plot window size to fit two rows, one column view
plot(sales_em, main = "Retail Sales: Electronic Shopping and \nMail-Order Houses", 
     xlab = "Time", ylab = "$ in millions")           #re-plot sales_em with recession bands
nberShade()
lines(sales_em)
plot(t, sales_total, type = "l", main = "Retail Sales: Total (including Food Services)",                                                
     xlab = "Time", ylab = "$ in millions")           #plot sales_total with recession bands
nberShade()
lines(t, sales_total, col = "navyblue")
par(mfrow = c(1,1))                                
                                                      #convert plot windows back to single plot view

```

> ##### c) Plotting ACF/PACF of data
```{r, results = "hide", message = FALSE, fig.show = "hide"}
ggAcf(sales_em)                  #plot Acf(autocorrelation function) of data as ggplot type
ggPacf(sales_em)                 #plot Pacf (partial autocorrelation function) of data as ggplot type

```

> ##### d) Fitting linear and non-linear models and comparing
```{r, results = "hide", message = FALSE, fig.show = "hide"}
t_mod1 <- tslm(sales_em ~ trend)    #create linear model including trend dummy
plot1 <- ggplot() + geom_line(data = as.data.frame(sales_em), aes(x = t, y = sales_em[1:335])) +
      geom_line(data = as.data.frame(t_mod1$fit), aes(x = t, y = t_mod1$fit), col = "red", lwd = 1) +
      ggtitle("Trend Model 1") +
      ylab("sales_em") +
      xlab("Time")                  
                     #create ggplot the model 1(t_mod1) in red over the actual data (sales_em) as "plot1"

lsales_em <- log(sales_em)             #take natural log of sales_em as "lsales_em"
t_mod2 <- tslm(lsales_em ~ trend)      #create natural log model including trend
plot2 <- ggplot() + geom_line(data = as.data.frame(sales_em), aes(x = t, y = lsales_em[1:335])) +
      geom_line(data = as.data.frame(t_mod2$fit), aes(x = t, y = t_mod2$fit), col = "red", lwd = 1) +
      ggtitle("Trend Model 2") +
      ylab("ln(sales_em)") +
      xlab("Time")                     
                     #create ggplot the model 2(t_mod2) in red over the actual data (sales_em) as "plot2"

grid.arrange(plot1, plot2, nrow = 2)   
#arrange 2 rows in a single window to plot and visually compare both models (similar to par(mfrow) function for a ggplot)

```

> ##### e) Plotting residuals vs fitted values for both trend models
```{r, results = "hide", message = FALSE, fig.show = "hide"}  
plot3 <- ggplot() + geom_point(aes(x = as.numeric(t_mod1$fit), y = as.numeric(t_mod1$res))) +
      geom_line(aes(x = as.numeric(t_mod1$fit), y = 0), col = "red") +
      geom_line(aes(x = 0, y = t_mod1$res), col = "red") +
      ggtitle("Trend Model 1") +
      xlab("Fitted Values") +
      ylab("Residuals")                   
                     #create plot of model 1 fitted values vs residuals as numerics (to avoid warning) as "plot3"
plot3                #return plot3


plot4 <- ggplot() + geom_point(aes(x = as.numeric(t_mod2$fit), y = as.numeric(t_mod2$res))) +
      geom_line(aes(x = as.numeric(t_mod2$fit), y = 0), col = "red") +
      ggtitle("Trend Model 2") +
      xlab("Fitted Values") +
      ylab("Residuals") 
                    #create plot of model 2 fitted values vs residuals as numerics (to avoid warning) as "plot4"
plot4               #return plot4


plot4a <- plot4 + geom_line(aes(x = 9.05, y = as.numeric(t_mod2$res)), col = "skyblue2", lwd = 0.25) + geom_line(aes(x = 9.7, y = as.numeric(t_mod2$res)), col = "skyblue2", lwd = 0.25)  
                   #add blue lines to plot 4 and save as "plot4a" 

plot4a             #return plot4a
plot(lsales_em, main = "Retail Sales: Electronic Shopping and \nMail-Order Houses", 
     xlab = "Time", ylab = "ln(sales_em)") #plot lsales_em 
nberShade()                                #gray recession bands
lines(lsales_em)                           #overlay lsales_em over bands
abline(h = 9.05, col = "skyblue2")         #create blue lines corresponding to plot4a 
abline(h = 9.7, col = "skyblue2")

```

> ##### f) Plotting Residual histograms for both models
```{r, results = "hide", message = FALSE, fig.show = "hide"}
truehist(t_mod1$res, col = "skyblue", xlab = "Residuals", ylab = "Fraction",  
         main = "Trend Model 1 \nResiduals Histogram", xlim = c(-20000, 20000)) #plot histogram of t_mod1 
xr <- rnorm(1000000, mean(t_mod1$res), sd(t_mod1$res))  
 #create a sample normal distribution from 1 mil. random values about t_mod1's residual mean and variance as "xr"
lines(density(xr), col = "red", lwd = 2)                #plot "xr" line
lines(density(t_mod1$res), col = "darkblue", lwd = 2)   #plot density distribution of t_mod1 residuals
legend(x = "topright", legend = c("Density", "Normal Distribution"), 
       col = c("darkblue", "red"), lty = 1, lwd = 2, bty = "n")  
 #create legend for both distribution lines with corresponding color scheme
```
```{r, results = "hide", message = FALSE, fig.show = "hide"}
truehist(t_mod2$res, col = "skyblue", xlab = "Residuals", ylab = "Fraction",
         main = "Trend Model 2 \nResiduals Histogram", xlim = c(-0.6, 0.6))     #plot histogram of t_mod2
xr <- rnorm(1000000, mean(t_mod2$res), sd(t_mod2$res))  
 #create a sample normal distribution from 1 mil. random values about t_mod2's residual mean and variance as "xr"
lines(density(xr), col = "red", lwd = 2)                #plot new "xr" line
lines(density(t_mod2$res), col = "darkblue", lwd = 2)   #plot density distribution of t_mod2 residuals
legend(x = "topright", legend = c("Density", "Normal Distribution"), 
       col = c("darkblue", "red"), lty = 1, lwd = 2, bty = "n")  
  #create legend for both distribution lines with corresponding color scheme

```

> ##### g) Getting diagnostic statistics
```{r, results = "hide", message = FALSE, fig.show = "hide"}
summary(t_mod1)           #return summary statistics of t_mod1
 
summary(t_mod2)           #return summary statistics of t_mod2
```

> ##### h) Getting model selection criteria AIC and BIC for both models 
```{r, results = "hide", message = FALSE, fig.show = "hide"}
AIC(t_mod1, t_mod2)       #return Akaike Info Criterion (AIC) of t_mod1 and t_mod2
BIC(t_mod1, t_mod2)       #return Bayesian Info Criterion (BIC) of t_mod1 and t_mod2

```

> ##### i) Using trend model 2 (t_mod2) to forecast 5 years ahead
```{r, results = "hide", message = FALSE, fig.show = "hide"}
fore1 <- forecast(t_mod2, h = 60)                              
                     #create forecast of model 2 for 60 monthly periods (5 years) as "fore1"
plot(fore1, main = "Trend Model 2", xlab = "Time", ylab = "lsales_em") #plot fore1
legend(x = "bottomright", legend = c("80% Prediction Interval", "95% Prediction Interval"), 
       fill = c("lightsteelblue3", "gray87"), bty = "n", cex = 1)    
                     #create legend that corresponds to the prediction intervals
legend(x = "bottom", "Point Forecast", col = "blue", lty = 1, lwd = 1.5, 
       bty = "n", cex = 1)                                           
                     #create legend that corresponds to the point forecast

```

> ### 2. Modeling and Forecasting Seasonality

> ##### a) Constructing seasonal aspect of lsales_em and looking at summary statistics
```{r, results = "hide", message = FALSE, fig.show = "hide"}
ggsubseriesplot(sales_em)            #ggplot of sales_em per year values
ggseasonplot(sales_em)               #ggplot of sales_em per year values for all years


par(mfrow = c(2,1))                    #create plot window with 2 rows
s_mod1 <- tslm(lsales_em ~ season + 0) #create model based on lsales_em including a seasonal dummy and intercept as "s_mod1"
summary(s_mod1)                        #return summary statistics of s_mod1
plot(s_mod1$fit, xlim = c(1992, 2020), ylab = "Seasonal Model 1",  
     main = "Seasonal Component of Dummy Model")  #plot s_mod1 fitted values as a time series

s_lsales_em <- stl(lsales_em, s.window = "periodic")  #create seasonally periodic stl decomposition as s_lsales_em
s_lsales_em <- s_lsales_em$time.series[,1]            #subset only the seasonal component
plot(s_lsales_em, ylab = "Seasonal ln(sales_em)", main = "Seasonal Adjustment using\nSTL Decomposition")                                #plot the stl decomposed seasonal component to compare with s_mod1
par(mfrow = c(1,1))                                   #set plot window back to 1

```

> ##### b) Plot seasonal factors
```{r, results = "hide", message = FALSE, fig.show = "hide"}
par(mfrow = c(2,1))                                      #create plot window with 2 rows
plot(s_mod1$coef, type = "l", main = "Seasonal Factors", xlab = "Season",
     ylab = "Seasonal Factors", lwd = 2, col = "forestgreen")  #plot coefficients of s_mod1
hist(s_mod1$res, main = "Histogram of Residuals", col = "steelblue2", xlim = c(-2, 2), xlab = "Seasonal Model 1 Residuals")                                 #plot histogram of s_mod1 residuals

```

> ##### c) Incorporate both trend and seasonal dummies to create full model and plot residuals vs fitted values
```{r, results = "hide", message = FALSE, fig.show = "hide"}
par(mfrow = c(1,1))                                    #set plot window back to 1
full_mod <- tslm(lsales_em ~ trend + season)           
       #create full model of lsales_em containing both trend and seasonality as "full_mod"
plot5 <- ggplot() + geom_point(aes(x = as.numeric(full_mod$fit), y = as.numeric(full_mod$res))) +
      geom_line(aes(x = as.numeric(full_mod$fit), y = 0), col = "red") +
      ggtitle("Full Model") +
      xlab("Fitted Values") +
      ylab("Residuals")                                #plot full_mod's residuals vs fitted values
plot5                                                  #return plot5


grid.arrange(plot5 + ylim(-0.4, 0.4), plot4, nrow = 2)
                            #plot and compare t_mod2 and full_mod for residuals vs fit

```

> ##### d) Summary statistics and Error metrics
```{r, results = "hide", message = FALSE, fig.show = "hide"}
summary(full_mod)                       #summary statistics of full_mod


AIC(t_mod1, t_mod2, s_mod1, full_mod)   #return AIC of both trend models, seasonal model, and full model
BIC(t_mod1, t_mod2, s_mod1, full_mod)   #return BIC of both trend models, seasonal model, and full model
```
```{r}
accuracy(full_mod)                      #return error metrics of full model
accuracy(t_mod2)                        #return error metrics of trend model 2 (the next best fit/model)

```

> ##### e) Using full model (full_mod) to forecast 5 years ahead
```{r, results = "hide", message = FALSE, fig.show = "hide"}
fore2 <- forecast(full_mod, h = 60)    #create forecast of full model for 60 monthly periods (5 years) as "fore2"
plot(fore2, main = "Full Model", xlab = "Time", ylab = "lsales_em") #plot fore2
plot(fore2, main = "Full Model", xlab = "Time", ylab = "lsales_em", #zoom into fore2 plot for 2017 to 2025
     xlim = c(2017, 2025))
legend(x = "bottomright", legend = c("80% Prediction Interval", "95% Prediction Interval"), 
       fill = c("lightsteelblue3", "gray87"), bty = "n", cex = 1.1)  
                                   #create legend that accounts for the prediction intervals
legend(x = "bottomleft", "Point Forecast", col = "blue", lty = 1,
       lwd = 2, bty = "n", cex = 1.1)
                                   #create legend that accounts for the point forecast
```

